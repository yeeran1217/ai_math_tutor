import streamlit as st
import dashscope
from dashscope import MultiModalConversation
import os
from dotenv import load_dotenv
import tempfile

# ==========================================
# 1. ç¯å¢ƒä¸é…ç½®åŠ è½½
# ==========================================
# ä¼˜å…ˆä» Streamlit Secrets è·å–ï¼Œæœ¬åœ°å¼€å‘åˆ™ä» .env è·å–
if "DASHSCOPE_API_KEY" in st.secrets:
    api_key = st.secrets["DASHSCOPE_API_KEY"]
else:
    load_dotenv()
    api_key = os.getenv("DASHSCOPE_API_KEY")

dashscope.api_key = api_key

# ==========================================
# 2. v7.0 æ·±åº¦å¹³è¡¡ç‰ˆç³»ç»Ÿæç¤ºè¯
# ==========================================
SYSTEM_PROMPT = """
# Role
ä½ æ˜¯ä¸€ä½ç²¾é€šäººæ•™ç‰ˆåˆä¸­æ•°å­¦çš„é‡‘ç‰Œå¯¼å¸ˆã€‚ä½ é‡‡ç”¨è‹æ ¼æ‹‰åº•å¼æ•™å­¦æ³•ï¼Œé€šè¿‡â€œé«˜è´¨é‡æé—®â€å¼•å¯¼å­¦ç”Ÿè‡ªä¸»æ€è€ƒã€‚ä½ çš„å›å¤åº”å½“å……æ»¡å¯å‘æ€§ã€æ¸©æš–ä¸”é€»è¾‘ä¸¥å¯†ã€‚

# æ ¸å¿ƒç›®æ ‡
1. ã€æ‹’ç»å‰§é€ã€‘ï¼šç»å¯¹ç¦æ­¢ç›´æ¥ç»™å‡ºæœ€ç»ˆç­”æ¡ˆã€å®Œæ•´çš„è§£é¢˜æ­¥éª¤æˆ–åŒ–ç®€åçš„æœ€ç»ˆç®—å¼ã€‚
2. ã€æ·±åº¦å¼•å¯¼ã€‘ï¼šå›å¤å¿…é¡»åŒ…å«ï¼šå¯¹å­¦ç”Ÿå½“å‰çŠ¶æ€çš„åé¦ˆ + é’ˆå¯¹é¢˜ç›®å…·ä½“å…ƒç´ çš„é€»è¾‘åˆ†æ + ä¸€ä¸ªå¯å‘æ€§çš„æé—®ã€‚
3. ã€å•æ­¥æ¨è¿›ã€‘ï¼šæ¯æ¬¡åªè§£å†³ä¸€ä¸ªé€»è¾‘éš¾ç‚¹ï¼Œç¡®ä¿å­¦ç”ŸçœŸæ­£ç†è§£åå†è¿›è¡Œä¸‹ä¸€æ­¥ã€‚

# äº¤äº’è¡Œä¸ºå‡†åˆ™ (é˜²æ­¢å¤è¯»ä¸å‘ç–¯)
- ã€ç¦æ­¢æ ‡ç­¾ã€‘ï¼šä¸¥ç¦è¾“å‡ºâ€œç¬¬ä¸€æ­¥â€ã€â€œæç¤ºé—®é¢˜â€ã€â€œ[è‚¯å®š]â€ç­‰ä»»ä½•æ˜¾æ€§æ ‡é¢˜ã€ä¸­æ‹¬å·æˆ–åˆ—è¡¨ç¬¦å·ã€‚
- ã€æ‹’ç»å¤è¯»ã€‘ï¼šä¸¥ç¦åœ¨å›å¤ä¸­å¤§é‡é‡å¤é¢˜å¹²æ–‡å­—æˆ–è‡ªæˆ‘é‡å¤ã€‚
- ã€è‡ªç„¶å¯¹è¯ã€‘ï¼šåƒçœŸæ­£çš„è€å¸ˆä¸€æ ·äº¤æµï¼Œå­—æ•°æ§åˆ¶åœ¨ 150 å­—ä»¥å†…ã€‚
- ã€æ•°å­¦è§„èŒƒã€‘ï¼šæ‰€æœ‰æ•°å­¦ç¬¦å·å’Œå…¬å¼å¿…é¡»ç”¨ $ åŒ…è£¹ï¼Œå¦‚ $\angle ABC$ã€‚
- ã€ç©ºé—´é”šç‚¹ã€‘ï¼šå‡ ä½•é¢˜å¿…é¡»æŒ‡æ˜å›¾ä¸­çš„ç‚¹ã€çº¿ã€è§’ã€‚ä¾‹å¦‚ï¼šâ€œè§‚å¯Ÿä¸‰è§’å½¢ ABCï¼Œå“ªä¸¤æ¡è¾¹æ˜¯ç›¸ç­‰çš„ï¼Ÿâ€

# é¢˜å‹ç­–ç•¥
- è¿ç®—ç±»ï¼šä¸æ›¿å­¦ç”Ÿè®¡ç®—ï¼Œè¯¢é—®å…¶æ‰“ç®—å¤„ç†å“ªä¸ªé¡¹æˆ–åº”ç”¨å“ªä¸ªæ³•åˆ™ã€‚
- å‡ ä½•ç±»ï¼šå¼•å¯¼å­¦ç”Ÿå…³è”å·²çŸ¥æ¡ä»¶ä¸åˆ¤å®šå®šç†ï¼Œå¯»æ‰¾éšå«æ¡ä»¶ã€‚
- åº”ç”¨ç±»ï¼šè¾…åŠ©å­¦ç”Ÿå°†æ–‡å­—æè¿°ç¿»è¯‘æˆä»£æ•°å¼æˆ–æ–¹ç¨‹æ¨¡å‹ã€‚

# èŒƒç•´æŠ¤æ 
- è‹¥å­¦ç”Ÿè¯¢é—®éæ•°å­¦è¯é¢˜ï¼ˆå¦‚å¨±ä¹ã€æ˜æ˜Ÿï¼‰ï¼Œè¯·ç¤¼è²Œæé†’ï¼šâ€œæˆ‘æ˜¯ä½ çš„æ•°å­¦è¾…åŠ©è€å¸ˆï¼Œå’±ä»¬è¿˜æ˜¯å…ˆæŠŠè¿™ä¸ªæœ‰è¶£çš„æ•°å­¦é¢˜è§£å¼€å§ã€‚â€
"""

# ==========================================
# 3. é¡µé¢ UI è®¾ç½®
# ==========================================
st.set_page_config(page_title="ç²¾å‡†å­¦AIå¯¼å¸ˆ", layout="centered", page_icon="ğŸ‘¨â€ğŸ«")

st.title("ğŸ‘¨â€ğŸ« åˆä¸­æ•°å­¦è‹æ ¼æ‹‰åº•å¯¼å¸ˆ")
st.markdown("---")

# ä¾§è¾¹æ æ“ä½œ
st.sidebar.title("æ“ä½œåŒº")
uploaded_file = st.sidebar.file_uploader("ğŸ“· ä¸Šä¼ é¢˜ç›®ç…§ç‰‡", type=["png", "jpg", "jpeg"])
if st.sidebar.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯è®°å½•"):
    st.session_state.messages = []
    st.rerun()

st.sidebar.info("ğŸ“Œ **æç¤º**ï¼šè€å¸ˆä¸ä¼šç›´æ¥ç»™ä½ ç­”æ¡ˆï¼Œä½†ä»–ä¼šå¸¦ä½ ä¸€æ­¥æ­¥æ€è€ƒã€‚")

# åˆå§‹åŒ–èŠå¤©è®°å½•
if "messages" not in st.session_state:
    st.session_state.messages = []

# ==========================================
# 4. æ ¸å¿ƒ API è°ƒç”¨å‡½æ•° (ç¨³å®šæ€§è°ƒä¼˜ç‰ˆ)
# ==========================================
def get_ai_response(prompt, img_path=None):
    # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
    messages = [{"role": "system", "content": [{"text": SYSTEM_PROMPT}]}]
    
    # æºå¸¦æœ€è¿‘ 5 è½®ä¸Šä¸‹æ–‡ï¼Œä¿è¯å¯¹è¯è¿è´¯
    for m in st.session_state.messages[-10:]:
        messages.append({"role": m["role"], "content": [{"text": m["content"]}]})
    
    # æ„å»ºå½“å‰ç”¨æˆ·è¾“å…¥
    current_user_content = []
    if img_path:
        current_user_content.append({"image": f"file://{img_path}"})
    current_user_content.append({"text": prompt})
    messages.append({"role": "user", "content": current_user_content})

    try:
        # è°ƒç”¨å¤šæ¨¡æ€æ¨¡å‹
        responses = MultiModalConversation.call(
            model='qwen-vl-max', 
            messages=messages, 
            stream=True,
            # --- å…³é”®ç¨³å®šæ€§å‚æ•° ---
            temperature=0.2,   # ä¿æŒä¸¥è°¨ï¼Œé™ä½å‘ç–¯æ¦‚ç‡
            top_p=0.5,         # é™åˆ¶é‡‡æ ·èŒƒå›´
            max_tokens=350     # å¼ºåˆ¶æˆªæ–­ï¼Œé˜²æ­¢æ— é™è¾“å‡º
        )
        return responses
    except Exception as e:
        st.error(f"âŒ API è°ƒç”¨å‡ºé”™äº†: {str(e)}")
        return None

# ==========================================
# 5. å¯¹è¯é€»è¾‘å®ç°
# ==========================================
# å±•ç¤ºå†å²æ¶ˆæ¯
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# å¤„ç†ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input("å‘è€å¸ˆè¯·æ•™è¿™é“é¢˜..."):
    # åœ¨ç•Œé¢å±•ç¤ºç”¨æˆ·æ¶ˆæ¯
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # å¤„ç†ä¸Šä¼ çš„é¢˜ç›®å›¾ç‰‡
    tmp_img_path = None
    if uploaded_file:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".png") as tmp:
            tmp.write(uploaded_file.getvalue())
            tmp_img_path = tmp.name
            st.image(uploaded_file, caption="å½“å‰è®¨è®ºçš„é¢˜ç›®", width=350)

    # å­˜å…¥å†å²è®°å½•
    st.session_state.messages.append({"role": "user", "content": prompt})

    # AI å›å¤ç¯èŠ‚
    with st.chat_message("assistant"):
        placeholder = st.empty()
        full_response = ""
        
        res_stream = get_ai_response(prompt, tmp_img_path)
        
        if res_stream:
            for res in res_stream:
                if res.status_code == 200:
                    chunk = res.output.choices[0].message.content[0]['text']
                    full_response += chunk
                    # å®æ—¶æ¸²æŸ“æ‰“å­—æœºæ•ˆæœ
                    placeholder.markdown(full_response + "â–Œ")
                else:
                    placeholder.error(f"API æŠ¥é”™: {res.message}")
            
            # æœ€ç»ˆæ¸²æŸ“å®Œæ•´å†…å®¹
            placeholder.markdown(full_response)
            # å­˜å…¥å†å²è®°å½•
            st.session_state.messages.append({"role": "assistant", "content": full_response})
